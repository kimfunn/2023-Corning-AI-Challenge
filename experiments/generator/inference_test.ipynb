{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'references'],\n",
       "        num_rows: 43579\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'answer', 'references'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'references'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"THUDM/webglm-qa\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    Question: {}\n",
    "    =========\n",
    "    {}\n",
    "    =========\n",
    "    Answer in:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what measures do film makers take to protect child actors in horror films or emotionally distressing scenes?\n",
      "['Not all stories about childhood are suitable for children. It is not uncommon for filmmakers to explore darker aspects of childhood in their films. Although telling these stories is important, if adequate protection measures aren’t taken, child actors can sustain psychological harm. Directors must be mindful of a child actor’s well-being and take care to shield the children they are working with from some darker themes of the material.', 'Linda has said in numerous interviews that she had no idea what she was doing at the time. But it begs the question: can starring in a horror movie as a child actor have an emotional effect during filming or even once the cameras stop rolling?', 'Do the directors usually try and avoid exposing the very young actors to the violence of such scenes, e.g. by clever dubbing and editing? Are there laws that require them to do so, just like there are ratings that prevent children from seeing some movies?', 'If a child is not comfortable with what they will be exposed with (such as mock rape and murder scenes), the director can not under law be allowed to use that child for that particular scene.', \"That isn't to say that a kid can do anything on a movie set. Laws protect children from certain flavors of exploitation, particularly of a sexual nature.\"]\n",
      "Directors must be mindful of a child actor’s well-being and take care to shield the children they are working with from some darker themes of the material[1]. They usually try and avoid exposing the very young actors to the violence of such scenes, e.g. by clever dubbing and editing[3]. There are laws that require them to do so, such as if a child is not comfortable with what they will be exposed with (such as mock rape and murder scenes)[4], the director can not under law be allowed to use that child for that particular scene. Laws also protect children from certain flavors of exploitation, particularly of a sexual nature.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"validation\"][0]['question'])\n",
    "print(dataset[\"validation\"][0]['references'])\n",
    "print(dataset[\"validation\"][0]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('vicgalle/gpt2-open-instruct-v1')\n",
    "tokenizer = AutoTokenizer.from_pretrained('vicgalle/gpt2-open-instruct-v1',truncation=True, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base')\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset['validation'][0:3]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what measures do film makers take to protect child actors in horror films or emotionally distressing scenes?'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what measures do film makers take to protect child actors in horror films or emotionally distressing scenes?\n",
      "['Not all stories about childhood are suitable for children. It is not uncommon for filmmakers to explore darker aspects of childhood in their films. Although telling these stories is important, if adequate protection measures aren’t taken, child actors can sustain psychological harm. Directors must be mindful of a child actor’s well-being and take care to shield the children they are working with from some darker themes of the material.', 'Linda has said in numerous interviews that she had no idea what she was doing at the time. But it begs the question: can starring in a horror movie as a child actor have an emotional effect during filming or even once the cameras stop rolling?', 'Do the directors usually try and avoid exposing the very young actors to the violence of such scenes, e.g. by clever dubbing and editing? Are there laws that require them to do so, just like there are ratings that prevent children from seeing some movies?', 'If a child is not comfortable with what they will be exposed with (such as mock rape and murder scenes), the director can not under law be allowed to use that child for that particular scene.', \"That isn't to say that a kid can do anything on a movie set. Laws protect children from certain flavors of exploitation, particularly of a sexual nature.\"]\n",
      "Why does Reddit search often fail.?\n",
      "['Yet more and more people are adding “Reddit” to their search inquiries to get more human, authentic, and useful results. This amounts to one massive desire path being carved into a computer system we use every day, as people try to fix their poor user experience. There’s a very real problem here that cannot be ignored forever.', 'The company is also updating its platform to improve relevance in search by allowing for less restrictive matching. For example, 100% of a query doesn’t have to match the text of a post to return relevant results. Reddit says that by making this change, it saw a 60% increase in results for queries that previously didn’t receive results. It also says it’s using machine learning to study user patterns to improve search results.', 'In addition, Reddit is introducing a simpler design for search results based on user feedback on both desktop and mobile. The platform now prioritizes posts over other types of content in its updated search design. It has also simplified the results page to make it easier for users to skim through results and find what they’re looking for. Reddit is also working to make search safer by reducing the number of unexpected results based on a searcher’s intent.', 'The fact that more and more people are “Reddit” to their searches has deep implications for marketers and business owners alike. It’s not just some weird quirky internet behavior. It’s the natural result of some business decisions that Google has made in the last decade.', 'But these days, even small-time websites can have financial links to the products they review and promote. Since so many people use Google to find product reviews, the lack of trust created by this prevalent affiliate marketing system causes people to seek unvarnished, unpaid reviews. Hence, again, adding “Reddit” to Google searches.']\n",
      "Why did the US fail in Vietnam and why is never really taught in schools?\n",
      "['Some lessons from Vietnam were clear: America fails when it attempts military action without a clear and achievable strategic goal, and when it fails to adequately understand the ideology of the enemy.', 'https://www.nytimes.com/1973/04/01/archives/have-we-learned-or-only-failed-the-lessons-of-vietnam-vietnam.html', 'For instance, one of the primary American history textbooks now used in the Garden Grove Unified School District includes more than 22 pages on the Vietnam War. It also asks students to respond to such questions as, “In what ways did U.S. military planners fail to understand the Vietnamese culture?” and, “The domino theory is still used by some politicians to explain global politics. Do you agree with the theory?”', 'Once too controversial to be taught in American high schools, the Vietnam War has slowly slipped into the curriculum, but only in a superficial way, educators say. Although many teachers consider Vietnam crucial to understanding American foreign policy and identify it as one of the key events in U.S. history, today’s high school students learn about the Vietnam War in much the same way they study other contemporary affairs--quickly and without much depth, educators say.', '“I think it’s a shame that high school students don’t learn more about this war, because the Vietnam War is still constantly referred to in public discourse as a standard to measure proposed military intervention,” said Jerry Starr, director of the Center for Social Studies Education in Pittsburgh, Pa., who has done extensive research on how the Vietnam War is taught in American schools.']\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(data['question'][i])\n",
    "    print(data['references'][i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    Question: {}\n",
    "    =========\n",
    "    {}\n",
    "    =========\n",
    "    Answer in:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://littlefoxdiary.tistory.com/46\n",
    "# 다양한 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (19942073.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [29]\u001b[0;36m\u001b[0m\n\u001b[0;31m    device = torch.device(‘cuda:0’)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(‘cuda:0’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline(model=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(model=\"gpt2\")\n",
    "outputs = generator(\"My tart needs some\", num_return_sequences=1, return_full_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 287, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gen_txt =[] \n",
    "gen_txtp =[] \n",
    "for i in range(1):\n",
    "    prompt = \"{} {} generate think\"\n",
    "    prompt = prompt.format(data['question'][i], data['references'][i])\n",
    "    generator = pipeline(model=\"gpt2\")\n",
    "    outputs = generator(str(prompt), num_return_sequences=1, return_full_text=False)\n",
    "    # generation = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    # print(generation)\n",
    "    gen_txtp.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'pieces'}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 287, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gen_txt =[] \n",
    "gen_txtp =[] \n",
    "for i in range(1):\n",
    "    prompt = \"{} {} generate think\"\n",
    "    prompt = prompt.format(data['question'][i], data['references'][i])\n",
    "    inputs = tokenizer.encode(prompt,add_special_tokens=True, return_tensors=\"pt\")\n",
    "    length = len(prompt)\n",
    "    max_l = length + 5\n",
    "    outputs = model.generate(inputs, pad_token_id=tokenizer.eos_token_id)\n",
    "    generation = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    # print(generation)\n",
    "    gen_txtp.append(generation[0][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' about']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_txtp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directors must be mindful of a child actor’s well-being and take care to shield the children they are working with from some darker themes of the material[1]. They usually try and avoid exposing the very young actors to the violence of such scenes, e.g. by clever dubbing and editing[3]. There are laws that require them to do so, such as if a child is not comfortable with what they will be exposed with (such as mock rape and murder scenes)[4], the director can not under law be allowed to use that child for that particular scene. Laws also protect children from certain flavors of exploitation, particularly of a sexual nature.\n",
      "Reddit search often fails because it does not prioritize posts over other types of content in its search design[3], and its matching system is too restrictive, meaning 100% of a query has to match the text of a post to return relevant results[2]. Additionally, the lack of trust in the affiliate marketing system created by Google and other websites has caused people to seek unvarnished reviews, which they can find on Reddit[5].\n",
      "The US failed in Vietnam because it attempted military action without a clear and achievable strategic goal, and failed to adequately understand the ideology of the enemy[1]. It is rarely taught in schools because the Vietnam War has slowly slipped into the curriculum, but only in a superficial way[4][5]. The primary American history textbooks now used in the Garden Grove Unified School District include some information on the Vietnam War, but it is usually not taught in depth[3]. According to Jerry Starr, director of the Center for Social Studies Education in Pittsburgh, Pa., the Vietnam War is still constantly referred to in public discourse as a standard to measure proposed military intervention, but high school students don't learn enough about the war[5].\n"
     ]
    }
   ],
   "source": [
    "print(data['answer'][0])\n",
    "print(data['answer'][1])\n",
    "print(data['answer'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert_score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from bert_score) (2.0.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from bert_score) (1.3.1)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from bert_score) (4.35.0)\n",
      "Requirement already satisfied: numpy in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from bert_score) (1.21.0)\n",
      "Requirement already satisfied: requests in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from bert_score) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /home/dilab/.local/lib/python3.8/site-packages (from bert_score) (4.65.0)\n",
      "Requirement already satisfied: matplotlib in /home/dilab/.local/lib/python3.8/site-packages (from bert_score) (3.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/dilab/.local/lib/python3.8/site-packages (from bert_score) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/dilab/.local/lib/python3.8/site-packages (from packaging>=20.9->bert_score) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/dilab/.local/lib/python3.8/site-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/dilab/.local/lib/python3.8/site-packages (from pandas>=1.0.1->bert_score) (2022.1)\n",
      "Requirement already satisfied: filelock in /home/dilab/.local/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (1.12)\n",
      "Requirement already satisfied: networkx in /home/dilab/.local/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /home/dilab/.local/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->bert_score) (68.2.2)\n",
      "Requirement already satisfied: wheel in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->bert_score) (0.41.3)\n",
      "Requirement already satisfied: cmake in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.0.0->bert_score) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.0.0->bert_score) (16.0.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from transformers>=3.0.0->bert_score) (0.17.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from transformers>=3.0.0->bert_score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/dilab/.local/lib/python3.8/site-packages (from transformers>=3.0.0->bert_score) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from transformers>=3.0.0->bert_score) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from transformers>=3.0.0->bert_score) (0.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/dilab/.local/lib/python3.8/site-packages (from matplotlib->bert_score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/dilab/.local/lib/python3.8/site-packages (from matplotlib->bert_score) (4.37.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/dilab/.local/lib/python3.8/site-packages (from matplotlib->bert_score) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/dilab/.local/lib/python3.8/site-packages (from matplotlib->bert_score) (9.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from requests->bert_score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from requests->bert_score) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dilab/.local/lib/python3.8/site-packages (from requests->bert_score) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from requests->bert_score) (2023.7.22)\n",
      "Requirement already satisfied: fsspec in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=3.0.0->bert_score) (2023.9.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert_score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dilab/.local/lib/python3.8/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/dilab/anaconda3/envs/jam/lib/python3.8/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Installing collected packages: bert_score\n",
      "Successfully installed bert_score-0.3.13\n"
     ]
    }
   ],
   "source": [
    "!pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.1498604465709729,\n",
       "  'p': 0.753968253968254,\n",
       "  'f': 0.24809601452884164},\n",
       " 'rouge-2': {'r': 0.08262108262108263,\n",
       "  'p': 0.6410256410256411,\n",
       "  'f': 0.1463162023876479},\n",
       " 'rouge-l': {'r': 0.13816454013822435,\n",
       "  'p': 0.7169312169312169,\n",
       "  'f': 0.2303182367510639}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "rouge.get_scores(gen_txtp, data['answer'], avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e28774328c43b69cf6e4c474b45c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cffc086f60bb4b03a1aa8c70846ea23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1d9b84587b49baade1882b06c81188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac826bf5c04446d9c8b3d85bcebe284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f72d9170da94437bc41226e6c836646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd933e9f5e4d456494de5aab855742d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de95b6c47b3542c8916e3641c84fd3b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.51 seconds, 5.85 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "P, R, F1 = score(gen_txtp, data['answer'], lang='en', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb Cell 18\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(get_rouge_score(gen_txtp,data))\n",
      "\u001b[1;32m/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb Cell 18\u001b[0m line \u001b[0;36mget_rouge_score\u001b[0;34m(refs, cands)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(cands)):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(i)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     score \u001b[39m=\u001b[39m scorer\u001b[39m.\u001b[39mscore(refs[i], cands[i])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     scores\u001b[39m.\u001b[39mappend(score[\u001b[39m'\u001b[39m\u001b[39mrouge1\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m2\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m scores\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "print(get_rouge_score(gen_txtp,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'directors must be mindful of a child actor’s well-being and take care to shield the children they are working with from some darker themes of the material'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_txtp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb Cell 17\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m calculate_rouge(gen_txtp[\u001b[39m0\u001b[39;49m],data[\u001b[39m'\u001b[39;49m\u001b[39manswer\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m])\n",
      "\u001b[1;32m/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb Cell 17\u001b[0m line \u001b[0;36mcalculate_rouge\u001b[0;34m(candidate, reference)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_rouge\u001b[39m(candidate, reference):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m    candidate, reference: generated and ground-truth sentences\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     scores \u001b[39m=\u001b[39m rouge\u001b[39m.\u001b[39;49mget_scores([candidate], reference)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m~/anaconda3/envs/jam/lib/python3.8/site-packages/rouge/rouge.py:103\u001b[0m, in \u001b[0;36mRouge.get_scores\u001b[0;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[1;32m     98\u001b[0m     hyps_and_refs \u001b[39m=\u001b[39m [_ \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m hyps_and_refs\n\u001b[1;32m     99\u001b[0m                      \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(_[\u001b[39m0\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    100\u001b[0m                      \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(_[\u001b[39m1\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[1;32m    101\u001b[0m     hyps, refs \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mhyps_and_refs)\n\u001b[0;32m--> 103\u001b[0m \u001b[39massert\u001b[39;00m(\u001b[39misinstance\u001b[39m(hyps, \u001b[39mtype\u001b[39m(refs)))\n\u001b[1;32m    104\u001b[0m \u001b[39massert\u001b[39;00m(\u001b[39mlen\u001b[39m(hyps) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(refs))\n\u001b[1;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m avg:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "calculate_rouge(gen_txtp[0],data['answer'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb Cell 17\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m sc \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data)):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     sc_1 \u001b[39m=\u001b[39m calculate_rouge(gen_txtp[i],data[\u001b[39m'\u001b[39;49m\u001b[39manswer\u001b[39;49m\u001b[39m'\u001b[39;49m][i])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(sc_1)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     sc \u001b[39m=\u001b[39m sc \u001b[39m+\u001b[39m sc_1\n",
      "\u001b[1;32m/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb Cell 17\u001b[0m line \u001b[0;36mcalculate_rouge\u001b[0;34m(candidate, reference)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_rouge\u001b[39m(candidate, reference):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m    candidate, reference: generated and ground-truth sentences\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     scores \u001b[39m=\u001b[39m rouge\u001b[39m.\u001b[39;49mget_scores([candidate], reference)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m~/anaconda3/envs/jam/lib/python3.8/site-packages/rouge/rouge.py:103\u001b[0m, in \u001b[0;36mRouge.get_scores\u001b[0;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[1;32m     98\u001b[0m     hyps_and_refs \u001b[39m=\u001b[39m [_ \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m hyps_and_refs\n\u001b[1;32m     99\u001b[0m                      \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(_[\u001b[39m0\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    100\u001b[0m                      \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(_[\u001b[39m1\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[1;32m    101\u001b[0m     hyps, refs \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mhyps_and_refs)\n\u001b[0;32m--> 103\u001b[0m \u001b[39massert\u001b[39;00m(\u001b[39misinstance\u001b[39m(hyps, \u001b[39mtype\u001b[39m(refs)))\n\u001b[1;32m    104\u001b[0m \u001b[39massert\u001b[39;00m(\u001b[39mlen\u001b[39m(hyps) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(refs))\n\u001b[1;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m avg:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sc = 0\n",
    "for i in range(len(data)):\n",
    "    sc_1 = calculate_rouge(gen_txtp[i],data['answer'][i])\n",
    "    print(sc_1)\n",
    "    sc = sc + sc_1\n",
    "\n",
    "sc_av = sc / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERATED SEQUENCE 1 ===\n",
      "You are an AI assistant for answering questions about technical topics.\n",
      "    You are given the following extracted parts of long documents and a question. Provide a conversational answer.\n",
      "    Use the context as a source of information, but be sure to answer the question directly. You're\n",
      "    job is to provide the user a helpful summary of the information in the context if it applies to the question.\n",
      "    If you don't know the answer, just say \"Hmm, I'm not sure.\".\n",
      "\n",
      "    Question: what measures do film makers take to protect child actors in horror films or emotionally distressing scenes?\n",
      "    =========\n",
      "['Not all stories about childhood are suitable for children. It is not uncommon for filmmakers to explore darker aspects of childhood in their films. Although telling these stories is important, if adequate protection measures aren’t taken, child actors can sustain psychological harm. Directors must be mindful of a child actor’s well-being and take care to shield the children they are working with from some darker themes of the material.', 'Linda has said in numerous interviews that she had no idea what she was doing at the time. But it begs the question: can starring in a horror movie as a child actor have an emotional effect during filming or even once the cameras stop rolling?', 'Do the directors usually try and avoid exposing the very young actors to the violence of such scenes, e.g. by clever dubbing and editing? Are there laws that require them to do so, just like there are ratings that prevent children from seeing some movies?', 'If a child is not comfortable with what they will be exposed with (such as mock rape and murder scenes), the director can not under law be allowed to use that child for that particular scene.', \"That isn't to say that a kid can do anything on a movie set. Laws protect children from certain flavors of exploitation, particularly of a sexual nature.\"]\n",
      "\n",
      "['\\n']\n"
     ]
    }
   ],
   "source": [
    "generated_sequences = []\n",
    "\n",
    "for generated_sequence_idx, generated_sequence in enumerate(sequences):\n",
    "    print(\"=== GENERATED SEQUENCE {} ===\".format(generated_sequence_idx + 1))\n",
    "    generated_sequence = generated_sequence.tolist()\n",
    "\n",
    "    # Decode text\n",
    "    text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n",
    "    print(text)\n",
    "\n",
    "    # Add the prompt at the beginning of the sequence. Remove the excess text that was used for pre-processing\n",
    "    total_sequence = (\n",
    "        text[len(tokenizer.decode(encoded_prompt[0])) :]\n",
    "    )\n",
    "\n",
    "    generated_sequences.append(total_sequence)\n",
    "    print(generated_sequences)\n",
    "\n",
    "# generated_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb Cell 20\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m sequences:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m         gen_txt\u001b[39m.\u001b[39mappend(seq[\u001b[39m'\u001b[39;49m\u001b[39mgenerated_text\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m gen_txt\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "for seq in sequences:\n",
    "        gen_txt.append(seq['generated_text'])\n",
    "\n",
    "gen_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb Cell 20\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     prompt \u001b[39m=\u001b[39m prompt_template\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(dataset[\u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m][i][\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m+\u001b[39mprompt_template2\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(dataset[\u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m][i][\u001b[39m'\u001b[39m\u001b[39mreferences\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m+\u001b[39mprompt_template3\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     sequences \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     prompt,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     do_sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     top_k\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     top_p \u001b[39m=\u001b[39;49m \u001b[39m0.9\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     temperature \u001b[39m=\u001b[39;49m \u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     eos_token_id\u001b[39m=\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     max_length\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, \u001b[39m# can increase the length of sequence\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m sequences:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.104.112.184/home/dilab/jam/rag2/ClosedAI/experiments/generator/inference_test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m         gen_txt\u001b[39m.\u001b[39mappend(seq[\u001b[39m'\u001b[39m\u001b[39mgenerated_text\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/jam/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/jam/lib/python3.8/site-packages/transformers/generation/utils.py:1511\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m \u001b[39m# 3. Define model inputs\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[39m# inputs_tensor has to be defined\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[39m# model_input_name is defined if model-specific keyword input is passed\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m \u001b[39m# otherwise model_input_name is None\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[39m# all model-specific keyword inputs are removed from `model_kwargs`\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m inputs_tensor, model_input_name, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_model_inputs(\n\u001b[1;32m   1509\u001b[0m     inputs, generation_config\u001b[39m.\u001b[39mbos_token_id, model_kwargs\n\u001b[1;32m   1510\u001b[0m )\n\u001b[0;32m-> 1511\u001b[0m batch_size \u001b[39m=\u001b[39m inputs_tensor\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1513\u001b[0m \u001b[39m# 4. Define other model kwargs\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39moutput_attentions\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m generation_config\u001b[39m.\u001b[39moutput_attentions\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    prompt = prompt_template+str(dataset[\"validation\"][i]['question'])+prompt_template2+str(dataset[\"validation\"][i]['references'])+prompt_template3\n",
    "    sequences = model.generate(\n",
    "    prompt,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    top_p = 0.9,\n",
    "    temperature = 0.2,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_length=200, # can increase the length of sequence\n",
    ")\n",
    "\n",
    "    for seq in sequences:\n",
    "        gen_txt.append(seq['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "korbias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
